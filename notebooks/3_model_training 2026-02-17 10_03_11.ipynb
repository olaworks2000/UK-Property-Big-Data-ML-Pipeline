{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88cc6339-08f5-4eb8-a7cc-53a2a7653181",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serverless ML environment configured. Temp path set to: /Volumes/workspace/default/uk_land_registry/ml_temp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# --- TECHNICAL REQUIREMENT: Serverless ML Scratch Space ---\n",
    "# We must point Spark ML to a UC Volume for temporary checkpointing\n",
    "temp_ml_path = \"/Volumes/workspace/default/uk_land_registry/ml_temp\"\n",
    "\n",
    "# Ensure the directory exists\n",
    "dbutils.fs.mkdirs(temp_ml_path)\n",
    "\n",
    "# Set the environment variable so the CrossValidator knows where to 'spill' data\n",
    "os.environ['SPARKML_TEMP_DFS_PATH'] = temp_ml_path\n",
    "\n",
    "print(f\"Serverless ML environment configured. Temp path set to: {temp_ml_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d0eb1f2-0292-4769-af09-5a697a315d24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Algorithm 1: Decision Tree (with CV)...\nTraining Algorithm 2: Random Forest...\nTraining Algorithm 3: Logistic Regression...\nNotebook 3 Complete: 3 Algorithms Trained and Serialized.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# 1. Load our Scaled Silver Data\n",
    "data = spark.read.parquet(\"/Volumes/workspace/default/uk_land_registry/silver_engineered_parquet\")\n",
    "\n",
    "# 2. Data Splitting Strategy\n",
    "train_df, test_df = data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# --- TECHNICAL REQUIREMENT: Define Evaluator ---\n",
    "# This must be defined BEFORE the CrossValidator uses it\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"type_label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "# --- TECHNICAL REQUIREMENT 2a: Implement at least 3 MLlib algorithms ---\n",
    "\n",
    "# Algorithm 1: Decision Tree (with Hyperparameter Tuning)\n",
    "dt = DecisionTreeClassifier(labelCol=\"type_label\", featuresCol=\"scaled_features\")\n",
    "paramGrid = ParamGridBuilder().addGrid(dt.maxDepth, [5, 10]).build()\n",
    "\n",
    "cv = CrossValidator(estimator=dt, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    evaluator=evaluator, \n",
    "                    numFolds=3)\n",
    "\n",
    "print(\"Training Algorithm 1: Decision Tree (with CV)...\")\n",
    "dt_model = cv.fit(train_df)\n",
    "\n",
    "# Algorithm 2: Random Forest\n",
    "print(\"Training Algorithm 2: Random Forest...\")\n",
    "rf = RandomForestClassifier(labelCol=\"type_label\", featuresCol=\"scaled_features\", numTrees=10)\n",
    "rf_model = rf.fit(train_df)\n",
    "\n",
    "# Algorithm 3: Logistic Regression\n",
    "print(\"Training Algorithm 3: Logistic Regression...\")\n",
    "lr = LogisticRegression(labelCol=\"type_label\", featuresCol=\"scaled_features\", maxIter=10)\n",
    "lr_model = lr.fit(train_df)\n",
    "\n",
    "# --- TECHNICAL REQUIREMENT 2a: Model Serialization ---\n",
    "# Saving the best version of each algorithm\n",
    "dt_model.bestModel.write().overwrite().save(\"/Volumes/workspace/default/uk_land_registry/models/best_dt_model\")\n",
    "rf_model.write().overwrite().save(\"/Volumes/workspace/default/uk_land_registry/models/rf_model\")\n",
    "lr_model.write().overwrite().save(\"/Volumes/workspace/default/uk_land_registry/models/lr_model\")\n",
    "\n",
    "print(\"Notebook 3 Complete: 3 Algorithms Trained and Serialized.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "3_model_training 2026-02-17 10:03:11",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}