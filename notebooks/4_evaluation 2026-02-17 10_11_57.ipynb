{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42c3d3bc-bc35-45d0-a0ae-454e21b9a969",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winner Model (Logistic Regression) Accuracy: 0.3541\nWeighted Precision: 0.2882\nWeighted Recall: 0.3541\n--- MODEL INTERPRETATION DATA ---\nCoefficient Matrix (Rows=Labels, Cols=Features):\nDenseMatrix([[-1.98333005],\n             [-1.17752791],\n             [ 1.34835099],\n             [-0.06797972],\n             [ 1.88048669]])\nIntercept Vector per Class:\n[0.6915935342989182,0.6570068166322911,0.5469963971895659,0.2878638930163585,-2.183460641137134]\nProperty Type 0 (Label 0) influence by Price: -1.9833\nProperty Type 1 (Label 1) influence by Price: -1.1775\nProperty Type 2 (Label 2) influence by Price: 1.3484\nProperty Type 3 (Label 3) influence by Price: -0.0680\nProperty Type 4 (Label 4) influence by Price: 1.8805\nNotebook 4 Complete: Winner metrics calculated and Gold Layer exported.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Load the WINNING Model (Logistic Regression) and Test Data\n",
    "# We point it to the folder we saved in Notebook 3\n",
    "model = LogisticRegressionModel.load(\"/Volumes/workspace/default/uk_land_registry/models/lr_model\")\n",
    "test_data = spark.read.parquet(\"/Volumes/workspace/default/uk_land_registry/silver_engineered_parquet\")\n",
    "\n",
    "# 2. Generate Predictions\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# 3. Calculate Key Metrics (Requirement 4a)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"type_label\", predictionCol=\"prediction\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "weightedPrecision = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "weightedRecall = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "\n",
    "print(f\"Winner Model (Logistic Regression) Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Weighted Precision: {weightedPrecision:.4f}\")\n",
    "print(f\"Weighted Recall: {weightedRecall:.4f}\")\n",
    "\n",
    "# --- 4. Feature Influence (Requirement 2a - Interpretation) ---\n",
    "# For Multiclass Logistic Regression, we use the Matrix\n",
    "\n",
    "try:\n",
    "    # coefficientMatrix gives us a row for each label (Detached, Flat, etc.)\n",
    "    # and a column for each feature (in our case, just Price)\n",
    "    matrix = model.coefficientMatrix\n",
    "    intercepts = model.interceptVector\n",
    "    \n",
    "    print(\"--- MODEL INTERPRETATION DATA ---\")\n",
    "    print(f\"Coefficient Matrix (Rows=Labels, Cols=Features):\\n{matrix}\")\n",
    "    print(f\"Intercept Vector per Class:\\n{intercepts}\")\n",
    "\n",
    "    # To make it report-ready:\n",
    "    for i, coeff in enumerate(matrix.toArray()):\n",
    "        print(f\"Property Type {i} (Label {i}) influence by Price: {coeff[0]:.4f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Could not extract coefficients directly: {str(e)}\")\n",
    "\n",
    "# 5. Export Final Gold Data for Dashboard 2 (Model Performance)\n",
    "# We keep this as 100k rows so Tableau doesn't lag.\n",
    "gold_evaluation = predictions.select(\"Price\", \"type_label\", \"prediction\").limit(100000)\n",
    "gold_evaluation.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"/Volumes/workspace/default/uk_land_registry/gold_model_performance\")\n",
    "\n",
    "print(\"Notebook 4 Complete: Winner metrics calculated and Gold Layer exported.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "4_evaluation 2026-02-17 10:11:57",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}